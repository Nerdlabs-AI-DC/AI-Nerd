Migrating from Chat Completions
1. Update generation endpoints
Start by updating your generation endpoints from Chat Completions to Responses.

Chat Completions

With Chat Completions, you need to create an array of messages that specifify different roles and content for each role.

Generate text from a model
from openai import OpenAI
    client = OpenAI()

    completion = client.chat.completions.create(
        model="gpt-5",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Hello!"}
        ]
    )
    print(completion.choices[0].message.content)
Responses

With Responses, you can separate instructions and input at the top-level. The API shape is similar to Chat Completions but has cleaner semantics.

Generate text from a model
from openai import OpenAI
    client = OpenAI()

    response = client.responses.create(
        model="gpt-5",
        instructions="You are a helpful assistant.",
        input="Hello!"
    )
    print(response.output_text)
2. Update multi-turn conversations
If you have multi-turn conversations in your application, update your context logic.

Chat Completions

In Chat Completions, you have to store and manage context yourself.

Multi-turn conversation
messages = [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "What is the capital of France?"}
    ]
    res1 = client.chat.completions.create(model="gpt-5", messages=messages)
    
    messages.append({"role": "assistant", "content": res1.choices[0].message.content})
    messages.append({"role": "user", "content": "And its population?"})

    res2 = client.chat.completions.create(model="gpt-5", messages=messages)
Responses

With Responses, you no longer need to manage context yourself. Simply pass the previous response ID to the next API call and the model will automatically utilize relevant previous context.

Multi-turn conversation
from openai import OpenAI
    client = OpenAI()

    response = client.responses.create(
        model="gpt-5",
        instructions="You are a helpful assistant.",
        input="Hello!"
    )
    print(response.output_text)
Some organizations—such as those with Zero Data Retention (ZDR) requirements—cannot use the Responses API in a stateful way due to compliance or data retention policies. To support these cases, OpenAI offers encrypted reasoning items, allowing you to keep your workflow stateless while still benefiting from reasoning items.

To use encrypted reasoning items:

add ["reasoning.encrypted_content"] to the include field
set store==false in the store field
The API will then return an encrypted version of the reasoning tokens, which you can pass back in future requests just like regular reasoning items. For ZDR organizations, OpenAI enforces store=false automatically. When a request includes encrypted_content, it is decrypted in-memory (never written to disk), used for generating the next response, and then securely discarded. Any new reasoning tokens are immediately encrypted and returned to you, ensuring no intermediate state is ever persisted.

For ZDR organizations, OpenAI enforces store=false automatically. When a request includes encrypted_content, it is decrypted in-memory (never written to disk), used for generating the next response, and then securely discarded. Any new reasoning tokens are immediately encrypted and returned to you, ensuring no intermediate state is ever persisted.

3. Update tools usage
If your application has use cases that would benefit from OpenAI's native tools, you can update your tool calls to use OpenAI's tools out of the box.

Chat Completions

With Chat Completions, you cannot use OpenAI's tools natively and have to write your own.

Web search tool
import requests

def web_search(query):
    r = requests.get(f"https://api.example.com/search?q={query}")
    return r.json().get("results", [])

completion = client.chat.completions.create(
    model="gpt-5",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who is the current president of France?"}
    ],
    functions=[
        {
            "name": "web_search",
            "description": "Search the web for information",
            "parameters": {
                "type": "object",
                "properties": {"query": {"type": "string"}},
                "required": ["query"]
            }
        }
    ]
)
Responses

With Responses, you can simply specify the tools that you are interested in.

Web search tool
answer = client.responses.create(
    model="gpt-5",
    input="Who is the current president of France?",
    tools=[{"type": "web_search_preview"}]
)
print(answer.output_text)